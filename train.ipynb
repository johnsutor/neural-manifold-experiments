{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_name: 2024-04-23_16-28-17\n",
      "seed: 42\n",
      "cpu: false\n",
      "mixed_precision: 'no'\n",
      "learning_rate: 1\n",
      "epochs: 51\n",
      "shuffle: true\n",
      "num_workers: 4\n",
      "pin_memory: true\n",
      "batch_size: 4096\n",
      "dataset:\n",
      "  train_kwargs:\n",
      "    root: /mnt/home/acanatar/ceph/manifold-experiments/data\n",
      "    split: train\n",
      "    download: true\n",
      "  train_name: moving_mnist\n",
      "  val_kwargs:\n",
      "    root: /mnt/home/acanatar/ceph/manifold-experiments/data\n",
      "    split: test\n",
      "    download: true\n",
      "  val_name: moving_mnist\n",
      "  frames_per_clip: 6\n",
      "manifold:\n",
      "  calculate:\n",
      "  - ellipsoid\n",
      "  - knn\n",
      "  - lstsq\n",
      "  calculate_every: 10\n",
      "  sampled_classes: 10\n",
      "  examples_per_class: 128\n",
      "  return_nodes:\n",
      "  - conv1\n",
      "  - layer1.0.conv1\n",
      "  - layer1.0.conv2\n",
      "  - layer1.1.conv1\n",
      "  - layer1.1.conv2\n",
      "  - layer2.0.conv1\n",
      "  - layer2.0.conv2\n",
      "  - layer2.1.conv1\n",
      "  - layer2.1.conv2\n",
      "  - layer3.0.conv1\n",
      "  - layer3.0.conv2\n",
      "  - layer3.1.conv1\n",
      "  - layer3.1.conv2\n",
      "  - layer4.0.conv1\n",
      "  - layer4.0.conv2\n",
      "  - layer4.1.conv1\n",
      "  - layer4.1.conv2\n",
      "  train_dataset_kwargs:\n",
      "    root: /mnt/home/acanatar/ceph/manifold-experiments/data\n",
      "    train: true\n",
      "    download: true\n",
      "  train_dataset: mnist\n",
      "  val_dataset_kwargs:\n",
      "    root: /mnt/home/acanatar/ceph/manifold-experiments/data\n",
      "    train: false\n",
      "    download: true\n",
      "  val_dataset: mnist\n",
      "model:\n",
      "  type: mmcr\n",
      "  encoder:\n",
      "    type: resnet18\n",
      "    weights: null\n",
      "    kwargs:\n",
      "      pretrained: false\n",
      "      in_chans: 1\n",
      "      num_classes: 0\n",
      "      global_pool: ''\n",
      "  classification_type: null\n",
      "  classification_kwargs: {}\n",
      "  autoregressive_type: null\n",
      "  autoregressive_kwargs: {}\n",
      "  projection_kwargs:\n",
      "    features:\n",
      "    - 2048\n",
      "    - 512\n",
      "    - 128\n",
      "  norm: 1\n",
      "  manifold_loss: dimensionality\n",
      "  name: mmcr_l1\n",
      "optimizer:\n",
      "  type: lars\n",
      "  kwargs:\n",
      "    weight_decay: 1.0e-06\n",
      "    momentum: 0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"EXPERIMENT_ROOT\"] = \"/mnt/home/acanatar/ceph/manifold-experiments\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"101e8cacc42cb22ed02071571fb2017ddd6c5ade\"\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "try:\n",
    "    initialize(version_base=None, config_path=\"configs\")\n",
    "except:\n",
    "    hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "    initialize(version_base=None, config_path=\"configs\")\n",
    "    \n",
    "cfg=compose(config_name=\"mmcr_train.yaml\",\n",
    "            overrides=[\"+model.projection_kwargs.features=[2048,512,128]\",\n",
    "                       'model.manifold_loss=\"dimensionality\"',\n",
    "                       \"batch_size=4096\",\n",
    "                       \"dataset.frames_per_clip=6\"])\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "\n",
    "import hydra\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from hydra.core.utils import JobReturn, JobStatus\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from hydra.experimental.callback import Callback\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "# from wandb import Histogram\n",
    "\n",
    "from manifold_experiments.constants import HEADS, OPTIMIZERS\n",
    "from manifold_experiments.datasets import VideoDataset\n",
    "from manifold_experiments.manifold_models import (\n",
    "    MMCRTwoStageTwoHeadPredictor,\n",
    "    ProjectionHead,\n",
    "    TwoStageTwoHeadPredictor,\n",
    "    create_encoder,\n",
    ")\n",
    "from manifold_experiments.utils.flatten import flatten\n",
    "from manifold_experiments.utils.knn import manifold_knn\n",
    "from manifold_experiments.utils.least_square_regression import manifold_lstsq\n",
    "from manifold_experiments.utils.manifold_statistics import (\n",
    "    extract_activations,\n",
    "    get_feature_extractor,\n",
    "    make_manifold_data,\n",
    "    manifold_analysis,\n",
    ")\n",
    "\n",
    "\n",
    "class LogJobReturnCallback(Callback):\n",
    "    \"\"\"Log the job's return value or error upon job end\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.log = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "\n",
    "    def on_job_end(\n",
    "        self, config: DictConfig, job_return: JobReturn, **kwargs: Any\n",
    "    ) -> None:\n",
    "        if job_return.status == JobStatus.COMPLETED:\n",
    "            self.log.info(f\"Succeeded with return value: {job_return.return_value}\")\n",
    "        elif job_return.status == JobStatus.FAILED:\n",
    "            self.log.error(\"\", exc_info=job_return._return_value)\n",
    "        else:\n",
    "            self.log.error(\"Status unknown. This should never happen.\")\n",
    "\n",
    "def train(cfg: OmegaConf):\n",
    "    print(OmegaConf.to_yaml(cfg), flush=True)\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    accelerator = Accelerator(\n",
    "        cpu=cfg.cpu,\n",
    "        log_with=\"wandb\",\n",
    "        project_dir=\"./trials\",\n",
    "        mixed_precision=cfg.mixed_precision,\n",
    "    )\n",
    "\n",
    "    run_name = f\"{cfg.model.name}_{cfg.dataset.train_name}_loss_{cfg.model.manifold_loss}\"\n",
    "    run_name += f\"_lr_{cfg.learning_rate}_batch_{cfg.batch_size}_seed_{cfg.seed}\"\n",
    "\n",
    "\n",
    "    encoder = create_encoder(\n",
    "        model_name=cfg.model.encoder.type,\n",
    "        weights=cfg.model.encoder.weights,\n",
    "        **cfg.model.encoder.kwargs,\n",
    "    )\n",
    "\n",
    "    model_type = (\n",
    "        TwoStageTwoHeadPredictor\n",
    "        if cfg.model.type == \"default\"\n",
    "        else MMCRTwoStageTwoHeadPredictor\n",
    "    )\n",
    "\n",
    "    model = model_type(\n",
    "        encoder=encoder,\n",
    "\n",
    "        linear_head=HEADS[cfg.model.classification_type](**cfg.model.classification_kwargs)\n",
    "        if OmegaConf.select(cfg, \"model.classification_type\")\n",
    "        else None,\n",
    "\n",
    "        autoregressive_head=HEADS[cfg.model.autoregressive_type](**cfg.model.autoregressive_kwargs)\n",
    "        if OmegaConf.select(cfg, \"model.autoregressive_type\")\n",
    "        else None,\n",
    "\n",
    "        projector=ProjectionHead(**cfg.model.projection_kwargs)\n",
    "        if OmegaConf.select(cfg, \"model.projection_kwargs\")\n",
    "        else nn.Identity(),\n",
    "\n",
    "        norm=OmegaConf.select(cfg, \"model.norm\"),\n",
    "\n",
    "        manifold_loss=OmegaConf.select(cfg, \"model.manifold_loss\", default=\"capacity\"),\n",
    "    )\n",
    "\n",
    "    # Freeze layers up until the specified layer, if present\n",
    "    if OmegaConf.select(cfg, \"model.freeze_until\"):\n",
    "        for name, param in model.named_parameters():\n",
    "            if cfg.model.freeze_until != \"all\" and cfg.model.freeze_until in name:\n",
    "                break\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # model = model.to(accelerator.device)\n",
    "\n",
    "    # Load dataset\n",
    "    train_dataset = VideoDataset(\n",
    "        name=cfg.dataset.train_name,\n",
    "        frames_per_clip=cfg.dataset.frames_per_clip,\n",
    "        **cfg.dataset.train_kwargs,\n",
    "    )\n",
    "    val_dataset = VideoDataset(\n",
    "        name=cfg.dataset.val_name,\n",
    "        frames_per_clip=cfg.dataset.frames_per_clip,\n",
    "        **cfg.dataset.val_kwargs,\n",
    "    )\n",
    "    manifold_train_dataset = VideoDataset(\n",
    "        name=cfg.manifold.train_dataset,\n",
    "        **cfg.manifold.train_dataset_kwargs,\n",
    "    )\n",
    "    manifold_val_dataset = VideoDataset(\n",
    "        name=cfg.manifold.val_dataset,\n",
    "        **cfg.manifold.val_dataset_kwargs,\n",
    "    )\n",
    "    sampled_manifold_dataset = make_manifold_data(\n",
    "        manifold_train_dataset,\n",
    "        cfg.manifold.sampled_classes,\n",
    "        cfg.manifold.examples_per_class,\n",
    "    )\n",
    "\n",
    "    # Load dataloader\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=cfg.shuffle,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=cfg.pin_memory,\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=cfg.shuffle,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=cfg.pin_memory,\n",
    "    )\n",
    "\n",
    "    # Load optimizer and scheduler\n",
    "    optimizer = OPTIMIZERS[cfg.optimizer.type](\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=cfg.learning_rate,\n",
    "        **cfg.optimizer.kwargs,\n",
    "    )\n",
    "\n",
    "    model, optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, val_dataloader\n",
    "    )\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        # Analyze manifold\n",
    "        if epoch % cfg.manifold.calculate_every == 0:\n",
    "            with torch.no_grad():\n",
    "                manifold_statistics = {}\n",
    "                feature_extractor = get_feature_extractor(\n",
    "                    model.encoder, cfg.manifold.return_nodes\n",
    "                )\n",
    "                activations = extract_activations(\n",
    "                    sampled_manifold_dataset, feature_extractor\n",
    "                )\n",
    "                # if \"knn\" in cfg.manifold.calculate:\n",
    "                #     knn_results = manifold_knn(\n",
    "                #         model,\n",
    "                #         manifold_train_dataset,\n",
    "                #         manifold_val_dataset,\n",
    "                #     )\n",
    "                #     manifold_statistics.update(knn_results)\n",
    "\n",
    "                # # NOTE: This is only meaningful when performed on video datasets,\n",
    "                # # not on MNIST\n",
    "                # if \"lstsq\" in cfg.manifold.calculate:\n",
    "                #     lstsq_results = manifold_lstsq(model, val_dataset)\n",
    "                #     manifold_statistics.update(lstsq_results)\n",
    "\n",
    "                # analysis = manifold_analysis(activations, cfg.manifold.calculate)\n",
    "                # manifold_statistics.update(analysis)\n",
    "\n",
    "        # Train\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for data, label in tqdm(train_dataloader, desc=f\"Train Epoch {epoch}\"):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            losses = model.calculate_loss(data, label)\n",
    "            assert type(losses) is dict, \"Losses must be returned in a dictionary\"\n",
    "\n",
    "            loss = losses[model.manifold_loss]\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        val_losses = dict()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, label in tqdm(val_dataloader, desc=f\"Val Epoch {epoch}\"):\n",
    "                losses = model.calculate_loss(data, label)\n",
    "                assert type(losses) is dict, \"Losses must be returned in a dictionary\"\n",
    "                \n",
    "                if len(val_losses) == 0:\n",
    "                    for key, val in losses.items():\n",
    "                        val_losses[key] = [val.item()]\n",
    "                else:\n",
    "                    for key, val in losses.items():\n",
    "                        val_losses[key] += [val.item()]\n",
    "        val_losses = {key: np.mean(val) for key, val in val_losses.items()}\n",
    "\n",
    "        # Log to tensorboard\n",
    "        log_obj = {\n",
    "            \"train_loss\": train_loss / len(train_dataloader),\n",
    "            \"val_loss\": val_losses[model.manifold_loss],\n",
    "            \"epoch\": epoch,\n",
    "            **val_losses,\n",
    "            **manifold_statistics,\n",
    "        }\n",
    "\n",
    "        log_obj = flatten(log_obj)\n",
    "\n",
    "        accelerator.log(\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in log_obj.items()\n",
    "                if (\"singular_values\" not in key)\n",
    "            },\n",
    "            step=epoch,\n",
    "        )\n",
    "\n",
    "        # for key, value in log_obj.items():\n",
    "        #     try:\n",
    "        #         if \"singular_values\" in key and value is not None:\n",
    "        #             accelerator.get_tracker(\"aim\").tracker.log_artifact(\n",
    "        #                 Histogram(value), name=key, epoch=epoch\n",
    "        #             )\n",
    "        #     except Exception:\n",
    "        #         pass\n",
    "\n",
    "        accelerator.print(\n",
    "            f\"Epoch {epoch}: Train Loss {log_obj['train_loss']}, Val Loss {log_obj['val_loss']}\"\n",
    "        )\n",
    "\n",
    "    # os.makedirs(str(HydraConfig.get().job.num), exist_ok=True)\n",
    "    # accelerator.save(\n",
    "    #     model.state_dict(),\n",
    "    #     os.path.join(\n",
    "    #         HydraConfig.get().runtime.output_dir,\n",
    "    #         str(HydraConfig.get().job.num),\n",
    "    #         \"model.pth\",\n",
    "    #     ),\n",
    "    # )\n",
    "    # torch.save(\n",
    "    #     model.encoder.state_dict(),\n",
    "    #     os.path.join(\n",
    "    #         HydraConfig.get().runtime.output_dir,\n",
    "    #         str(HydraConfig.get().job.num),\n",
    "    #         \"encoder.pth\",\n",
    "    #     ),\n",
    "    # )\n",
    "    accelerator.end_training()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_name: ${now:%Y-%m-%d_%H-%M-%S}\n",
      "seed: 42\n",
      "cpu: false\n",
      "mixed_precision: 'no'\n",
      "learning_rate: 1\n",
      "epochs: 51\n",
      "shuffle: true\n",
      "num_workers: 4\n",
      "pin_memory: true\n",
      "batch_size: 4096\n",
      "dataset:\n",
      "  train_kwargs:\n",
      "    root: ${oc.env:EXPERIMENT_ROOT}/data\n",
      "    split: train\n",
      "    download: true\n",
      "  train_name: moving_mnist\n",
      "  val_kwargs:\n",
      "    root: ${oc.env:EXPERIMENT_ROOT}/data\n",
      "    split: test\n",
      "    download: true\n",
      "  val_name: moving_mnist\n",
      "  frames_per_clip: 6\n",
      "manifold:\n",
      "  calculate:\n",
      "  - ellipsoid\n",
      "  - knn\n",
      "  - lstsq\n",
      "  calculate_every: 10\n",
      "  sampled_classes: 10\n",
      "  examples_per_class: 128\n",
      "  return_nodes:\n",
      "  - conv1\n",
      "  - layer1.0.conv1\n",
      "  - layer1.0.conv2\n",
      "  - layer1.1.conv1\n",
      "  - layer1.1.conv2\n",
      "  - layer2.0.conv1\n",
      "  - layer2.0.conv2\n",
      "  - layer2.1.conv1\n",
      "  - layer2.1.conv2\n",
      "  - layer3.0.conv1\n",
      "  - layer3.0.conv2\n",
      "  - layer3.1.conv1\n",
      "  - layer3.1.conv2\n",
      "  - layer4.0.conv1\n",
      "  - layer4.0.conv2\n",
      "  - layer4.1.conv1\n",
      "  - layer4.1.conv2\n",
      "  train_dataset_kwargs:\n",
      "    root: ${oc.env:EXPERIMENT_ROOT}/data\n",
      "    train: true\n",
      "    download: true\n",
      "  train_dataset: mnist\n",
      "  val_dataset_kwargs:\n",
      "    root: ${oc.env:EXPERIMENT_ROOT}/data\n",
      "    train: false\n",
      "    download: true\n",
      "  val_dataset: mnist\n",
      "model:\n",
      "  type: mmcr\n",
      "  encoder:\n",
      "    type: resnet18\n",
      "    weights: null\n",
      "    kwargs:\n",
      "      pretrained: false\n",
      "      in_chans: 1\n",
      "      num_classes: 0\n",
      "      global_pool: ''\n",
      "  classification_type: null\n",
      "  classification_kwargs: {}\n",
      "  autoregressive_type: null\n",
      "  autoregressive_kwargs: {}\n",
      "  projection_kwargs:\n",
      "    features:\n",
      "    - 2048\n",
      "    - 512\n",
      "    - 128\n",
      "  norm: 1\n",
      "  manifold_loss: dimensionality\n",
      "  name: mmcr_l1\n",
      "optimizer:\n",
      "  type: lars\n",
      "  kwargs:\n",
      "    weight_decay: 1.0e-06\n",
      "    momentum: 0.9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: 100%|██████████| 3/3 [00:11<00:00,  3.79s/it]\n",
      "Val Epoch 0: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Accelerator' object has no attribute 'trackers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(cfg)\n",
      "Cell \u001b[0;32mIn[3], line 235\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    225\u001b[0m log_obj \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_losses[model\u001b[38;5;241m.\u001b[39mmanifold_loss],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmanifold_statistics,\n\u001b[1;32m    231\u001b[0m }\n\u001b[1;32m    233\u001b[0m log_obj \u001b[38;5;241m=\u001b[39m flatten(log_obj)\n\u001b[0;32m--> 235\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    236\u001b[0m     {\n\u001b[1;32m    237\u001b[0m         key: value\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m log_obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingular_values\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m    240\u001b[0m     },\n\u001b[1;32m    241\u001b[0m     step\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    242\u001b[0m )\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# for key, value in log_obj.items():\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m#         if \"singular_values\" in key and value is not None:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m#     except Exception:\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m#         pass\u001b[39;00m\n\u001b[1;32m    253\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Train Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/neural/lib/python3.11/site-packages/accelerate/accelerator.py:615\u001b[0m, in \u001b[0;36mAccelerator.on_main_process.<locals>._inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PartialState()\u001b[38;5;241m.\u001b[39mon_main_process(function)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/neural/lib/python3.11/site-packages/accelerate/accelerator.py:2479\u001b[0m, in \u001b[0;36mAccelerator.log\u001b[0;34m(self, values, step, log_kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;129m@on_main_process\u001b[39m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog\u001b[39m(\u001b[38;5;28mself\u001b[39m, values: \u001b[38;5;28mdict\u001b[39m, step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, log_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m {}):\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;124;03m    Logs `values` to all stored trackers in `self.trackers` on the main process only.\u001b[39;00m\n\u001b[1;32m   2456\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2479\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tracker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrackers:\n\u001b[1;32m   2480\u001b[0m         tracker\u001b[38;5;241m.\u001b[39mlog(values, step\u001b[38;5;241m=\u001b[39mstep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlog_kwargs\u001b[38;5;241m.\u001b[39mget(tracker\u001b[38;5;241m.\u001b[39mname, {}))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Accelerator' object has no attribute 'trackers'"
     ]
    }
   ],
   "source": [
    "train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (neural)",
   "language": "python",
   "name": "neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
